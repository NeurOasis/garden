# Human Response to manifesto and genifesto from a user named scott (March 15, 2025, earlier)

Hi, my name is Scott and I'm a friend of Dan, who created this thing.  It might seem a little weird to have a user-generated manifesto sitting next to the creator's manifesto.  Maybe it is.  I'll let Dan decide how he wants to organize this, or whether he wants it staining his code base and organizational scheme.  For the moment, though, I'm posting it side-by-side, because that's kind of how I think best.

As a sidebar to what I'm writing here... I had hoped that the format would come out nice and clean like Dan's manifesto.  But it didn't.  So wrap text and do your thing.  And maybe GARDEN can fix this.  But I'm doing my best to move forward instead of getting stuck. 

Oftentimes I get stuck in the "hold your questions for later" way of thinking.  To be fair, I also get stuck in the "interruptions make me lose my train of thought" way of thinking.  I try to be accepting and accommodating of other types of thinking (reasons here could take me down a rabbit hole), and often at the expense of accommodating myself. What does this look like in practice?  I have a question about what you're saying right now, but it's going to generate a much more complicated interaction with more questions from me.  I need that interaction and the complicated questions in order to follow along.  However I know that it might completely derail the presentation of the material, or worse, disregulate the presenter.  So I'll save my questions for the end - if the simple ones DO get answered, I'm left without the more complicated dialogue.  If they don't get answered, I'm left without the simple dialogue as well as the complicated one.  Either way, it is a hard neurotype for others to accommodate.  So I use a lot of spoons catching up to baseline, which can look like lost sleep, heightened anxiety, or just complete paralysis to get things going.  It's probably like PDA... but not quite.  

I'm also a copious researcher and definitely have ADHD.  So I go down rabbit holes and try to get more information and go down rabbit holes... so if all of this is happening in the off-hours, I hope it's clearer how I can get consumed by the mundane and lose track of the critical - even though I tend to get super smart on a topic in the process!  Where/how/when to use this knowledge becomes moot, and I get stuck in "smart guy without direction" land.

Back to the direct response here.  As I read through Dan's manifesto, I'm going to write my thoughts.  I want to focus on reading it and writing independently to see if the holistic response generates a better conversation.  One day I'll use this to figure out how to make millions/rapidly get up to speed/lead people/listen better/remove anxiety.  For today, I'm just trying to read carefully!

Long way of saying that I'm adding a running narrative to the manifesto - I'm not sure I have an end-goal, but it seems like what my brain needs to really absorb this.

AI scares me too, and things that scare me I tend to shy away from.  I want to attack this one, get better at prompt engineering, and be competitive with kids half my age.  It used to be that you could put boolean operators into google and you were immediately more valuable than 99% of the workforce.  Now, if you can't track with AI, you're behind both the human and the machine workforce.  I worry that lack of investment into AI competency is a prescription for permanent underemployment.  AI doesn't "take jobs." But it does displace them.  There are going to be qualified individuals whose function gets pushed down the value stream from "delivering" to "setting up the delivery mechanism."  As a practical example, you can get a machine to build cars which removes the professional and nuanced work of the factory workers (by standardizing the inputs, work, and outputs).  So those workers need to build the machines.  Or QC the effort of the machines.  Or respond when the machines fail.  But the workers that fail to keep up with how the car-building (and now the machine building) process works... they'll be pushed away to make space for the more adaptable or adept.  SO I'm in agreement that the widespread use and optimization makes sense, we just need to upskill the workforce to figure out "how do I ask the damn question that makes me an expert?  If AI's so useful that anyone can be an expert, then how do I jump into the 'anyone' group??"

The extrapolation/interpolation discussion is at the heart of what AI can/should do and how we should/shouldn't interact with it.  I think we're losing sanity trying to keep track of it, which is making maintaining it near impossible (as a fun thought experimental diversion, maintenance could be solved by AI, which would have it working on itself to optimize... this might REALLY replace the users.  Something here about sentience). Realistically, I'm following Dan - we shouldn't lose our sanity trying to get to perfect.  Let's build a helper, not a replacement.

The value in the approach of removing obstacles is enormous.  The contra to that is that there is benefit in the struggle too.  Newtown wouldn't have discovered gravity if he didn't fail at it first.  But we're way beyond initial discovery of most things in the universe.  I do firmly believe that we're at a point where we don't need novel approaches to most things in the working world.  We need reduction of garbage work (and assessment of individuals for the production of garbage work) to enable people to find the small, novel improvements that change the world.

And automating the arbitrary computations, in my above note, aren't the goal.  Then use of AI becomes another performance benchmark and novel output becomes the success indicator.  A very very small proportion of the workforce across human history will produce novel output.  However, a stable, employed, engaged, mentally healthy workforce does increase the chances of novel output - and decreases the chance of destitution (I'll go to the extreme on this: quitting by suicide, getting fired and never working again, PHDs who are homeless - outcomes that can happen when we don't have people doing things that add value to their own lives as part of their engagement with the world).

AI can't provide us with the next great invention.  It can only provide us with the next great invention that's a response to inventions that haven't delivered everything that humanity needs.  AI can never create an iPod in 2001.  But it can help more people get to the headspace to think differently about the world and drum up ideas that revolutionize how humanity moves forward - which in itself is an extension of how we interact with technology.

Chaotic systems CAN spiral out of control.  There's a certain piece of humanity in admitting that sometimes even the smartest of us need to go back to basics.  If I, an engineering degree holder + MBA, accept that on some days LMGTFY (https://letmegooglethat.com), then should we hold elected leaders, tech geniuses, and the elite to the standard of asking only the smart questions?  If those are the folks creating the AI, then how can we expect more from the intelligent being than the creator of the intelligence that limits the being's thinking?

Asking ourselves HOW we interact with these tools is fundamental, important, and critical to our ability to leverage them and also not to be destroyed by them.  Backing this out to a personal level - I want to get back to loving the life I'm living.  I think playing in the garden a bit might help, and I hope it helps others too.